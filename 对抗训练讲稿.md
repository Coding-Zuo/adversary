老师同学们好，我是左玉晖

今天我带来的内容是浅谈对抗训练

——————————

我们试想一下，如果将来真的像科幻片一样进入了人工智能万物互联的时代。

车都是自动驾驶的，人们都用VR或者AR来看手机。

车跟车之间的安全距离都是由人工智能来控制。

那么有没有什么隐患？

------

现在的无人驾驶场景比如这有个指示牌告诉智能车停下的话，学图像处理的人应该明白，我们可以通过cnn对这幅图进行啊目标检测，怎么怎么招，那么神经网络真的就很安全吗？

---

现在以神经网络为根基的深度学习，将来落地在人工智能时代其实有很多隐患的。

现在的神经网络鲁棒性都很差，特别依赖样本来学习。那么我们就需要研究更鲁棒能防御对抗样本攻击的模型。

所以对抗训练可以是一种防御手段。那么什么是对抗样本呢？

---

比如这个实验，针对输入的图像x我们可以识别出他57%是个熊猫

但是一旦加了一点噪声之后，加完之后的图像我们人眼还是能看出来是个熊猫

但是我们的模型居然把它识别成了一只长臂猿。

这个噪声就是对抗样本。

如果在大马路上，一辆无人驾驶汽车被攻击了，那么后果可想而知。

所以我认为人类肯定会走进智能时代，而走进去的一个重要指标就是智能技术的算法安全！所以这方面是很有发paper空间的。

---

那么一个对抗样本要满足什么条件

读

----

深度学习采用对抗思想的目前有两大类

一类是生成对抗网络

一类就是和对抗攻击相关的领域，关心的是模型在扰动下的稳健性

我今天也主要是想讲下面这种。研究对抗训练不是我的方向，只是最近有用到这方面的知识，才研究几天，可能有讲的不妥的地方。

----

研究意义

读

---

从数学定义角度，定义对抗训练的公式如下

解释公式

有一个难题是如何获取 delta x

sign 正数1负数-1 指的是 针对loss的输入x求偏导，得到梯度方向是正是负 乘以一个系数 得到。这个是GAN之父在ICLR2015论文上提出的 叫FGSM

而两年之后，他又提出改进，用sign寻找梯度方向太拘束，我直接求向量全方向上的梯度再乘以一个系数。

---

介绍

昨天我实验了一下，用这个FGM，在正在举办的机器阅读理解的比赛任务中提升了两个点。后面介绍

伪代码如下：读

----

在之后提出了PGD算法，认为FGM通过epsilon参数一下算出对抗扰动可能不是最优的。因此采用PGD进行了改进，多迭代了几次，慢慢找到最优的扰动。这个方法我还在实验中，还没有跑完结果。

伪代码如下：读

**最后更新参数只使用最后一个x+r算出来的梯度**。缺点就是会让训练变慢接近t倍

-----

然后接下来的研究就是围绕得到更优的扰动和提升训练速度

FreeAT 和YOPO 没有细看 不过多叙述了

FreeLB我看了一下他的论文

---

他在去年的自然语言理解基准榜单上得到了第一名

就是用对抗训练的思想。现在排在了第十一是微软研究的。

然后在对话阅读理解数据集上也是采用这个对抗思想，能力首次超过人类。是追一科技，论文还没来得及看

---

讲一下nlp中的对抗对手

读

----

读

因为nlp的输入其实就是one-hot向量，如果针对onehot进行扰动，每个扰动的距离恒为根号2 ，也不满足对抗样本的要求，所以基本上都是在embedding层来做扰动的

-----

FreeLB



---

然后是现在新兴的神经网络主流图神经网络

现在用GNN做认知推理是越来越常见的趋势

针对非欧空间的离散数据，也是相当容易被攻击的毒害的。

---

针对他的输入

















